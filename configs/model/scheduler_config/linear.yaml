scheduler:
    _target_: transformers.get_linear_schedule_with_warmup
    num_warmup_steps: 1500
    num_training_steps: 3000


scheduler_dict:
    interval: "step"  # The unit of the scheduler's step size. 'step' or 'epoch
    frequency: 1  # corresponds to updating the learning rate after every `frequency` epoch/step
    name: "linear_schedule_with_warmup"