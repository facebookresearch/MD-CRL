_target_: models.modules.resnet_ae.ResNetAE

latent_dim: ${model.z_dim}
width: 64
height: 64
num_channels: 3
upsampling_interpolation: nearest # options: nearest, bilinear, bicubic, trilinear

encoder_cnn:
  _target_: models.modules.resnet_ae.Encoder
  latent_dim: ${model.autoencoder.latent_dim}
  width: ${model.autoencoder.width}
  height: ${model.autoencoder.height}

  encoder_layers:
    resnet18:
      _target_: torchvision.models.resnet18
      progress: True
      pretrained: False
      num_classes: 1000 # ${model.autoencoder.latent_dim}
    mlp_layers:
      flatten:
        _target_: torch.nn.Flatten
      fc1:
        _target_: torch.nn.Linear
        in_features: 512 # 128
        out_features: 128
        bias: False

      BN1:
        _target_: torch.nn.BatchNorm1d
        num_features: ${model.autoencoder.encoder_cnn.encoder_layers.mlp_layers.fc1.out_features}

      fc1_nonlinearity:
        _target_: torch.nn.LeakyReLU 
        negative_slope: 0.1
    
      fc2:
        _target_: torch.nn.Linear
        in_features: 128 # 64
        out_features: ${model.autoencoder.latent_dim} # 64
        bias: False

      BN2:
        _target_: torch.nn.BatchNorm1d
        num_features: ${model.autoencoder.encoder_cnn.encoder_layers.mlp_layers.fc2.out_features}

decoder_cnn:
  _target_: models.modules.resnet_ae.Decoder
  latent_dim: ${model.autoencoder.latent_dim}
  width: ${model.autoencoder.width}
  height: ${model.autoencoder.height}
  num_channels: ${model.autoencoder.num_channels}

  mlp_layers:
      fc1:
        _target_: torch.nn.Linear
        in_features: ${model.autoencoder.latent_dim} # 128
        out_features: 128
        bias: False

      # BN1:
      #   _target_: torch.nn.BatchNorm1d
      #   num_features: ${model.autoencoder.decoder_cnn.mlp_layers.fc1.out_features}

      fc1_nonlinearity:
        _target_: torch.nn.LeakyReLU
        negative_slope: 0.1
    
      fc2:
        _target_: torch.nn.Linear
        in_features: 128
        out_features: 1024 # 64x4x4
        bias: False
      
      # BN2:
      #   _target_: torch.nn.BatchNorm1d
      #   num_features: ${model.autoencoder.decoder_cnn.mlp_layers.fc2.out_features}

      fc2_nonlinearity:
        _target_: torch.nn.LeakyReLU

  decoder_layers:

    ConvTranspose1:
      _target_: torch.nn.ConvTranspose2d
      in_channels: 64
      out_channels: 64
      kernel_size: 4
      stride: 2
      padding: 1
    
    # BN1:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.ConvTranspose1.out_channels}

    LeakyReLU1:
      _target_: torch.nn.LeakyReLU

    ConvTranspose2:
      _target_: torch.nn.ConvTranspose2d
      in_channels: 64
      out_channels: 32
      kernel_size: 4
      stride: 2
      padding: 1
    
    # BN2:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.ConvTranspose2.out_channels}

    LeakyReLU2:
      _target_: torch.nn.LeakyReLU

    ConvTranspose3:
      _target_: torch.nn.ConvTranspose2d
      in_channels: 32
      out_channels: 32
      kernel_size: 4
      stride: 2
      padding: 1

    # BN3:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.ConvTranspose3.out_channels}

    LeakyReLU3:
      _target_: torch.nn.LeakyReLU

    ConvTranspose4:
      _target_: torch.nn.ConvTranspose2d
      in_channels: 32
      out_channels: ${model.autoencoder.num_channels}
      kernel_size: 4
      stride: 2
      padding: 1

      # in_channelsx1x1 --> out_channelsx2x2
    # Upsample1:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx1x1 --> in_channelsx2x2

    # Conv1:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.latent_dim}
    #   out_channels: 64
    #   kernel_size: 2
    #   stride: 2
    #   padding: 1
    #   # in_channelsx2x2 --> out_channelsx2x2

    # BN1:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.Conv1.out_channels}

    # ReLU1:
    #   _target_: torch.nn.ReLU

    # Upsample2:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx2x2 --> in_channelsx4x4

    # Conv2:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv1.out_channels}
    #   out_channels: 32
    #   kernel_size: 3  # Adjust the kernel size as needed
    #   stride: 1
    #   padding: 1
    #   # in_channelsx4x4 --> out_channelsx4x4

    # BN2:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.Conv2.out_channels}

    # ReLU2:
    #   _target_: torch.nn.ReLU

    # Upsample3:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx4x4 --> in_channelsx8x8

    # Conv3:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv2.out_channels}
    #   out_channels: 16
    #   kernel_size: 3
    #   stride: 1
    #   padding: 1
    #   # in_channelsx8x8 --> out_channelsx8x8

    # BN3:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.Conv3.out_channels}

    # ReLU3:
    #   _target_: torch.nn.ReLU

    # Upsample4:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx8x8 --> in_channelsx16x16

    # Conv4:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv3.out_channels}
    #   out_channels: 8
    #   kernel_size: 3
    #   stride: 1
    #   padding: 1
    #   # in_channelsx16x16 --> out_channelsx16x16

    # ReLU4:
    #   _target_: torch.nn.ReLU

    # Upsample5:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx16x16 --> in_channelsx32x32

    # Conv5:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv4.out_channels}
    #   out_channels: 4
    #   kernel_size: 3
    #   stride: 1
    #   padding: 1
    #   # in_channelsx32x32 --> out_channelsx32x32

    # ReLU5:
    #   _target_: torch.nn.ReLU

    # Upsample6:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx32x32 --> in_channelsx64x64

    # Conv6:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv5.out_channels}
    #   out_channels: ${model.autoencoder.num_channels}
    #   kernel_size: 3
    #   stride: 1
    #   padding: 1
    #   # in_channelsx64x64 --> num_channelsx64x64

    # ReLU6:
    #   _target_: torch.nn.ReLU

