# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.


_target_: models.modules.resnet_ae.ResNetAE

latent_dim: ${model.z_dim}
width: 28
height: 28
num_channels: 3
upsampling_interpolation: nearest # options: nearest, bilinear, bicubic, trilinear

encoder_cnn:
  _target_: models.modules.resnet_ae.Encoder
  latent_dim: ${model.autoencoder.latent_dim}
  width: ${model.autoencoder.width}
  height: ${model.autoencoder.height}

  encoder_layers:
    resnet18:
      _target_: torchvision.models.resnet18
      progress: True
      pretrained: False
      num_classes: 1000 # ${model.autoencoder.latent_dim}
    mlp_layers:
      flatten:
        _target_: torch.nn.Flatten
      fc1:
        _target_: torch.nn.Linear
        in_features: 512 # 128
        out_features: 128
        bias: False

      BN1:
        _target_: torch.nn.BatchNorm1d
        num_features: ${model.autoencoder.encoder_cnn.encoder_layers.mlp_layers.fc1.out_features}

      fc1_nonlinearity:
        _target_: torch.nn.LeakyReLU 
        negative_slope: 0.1
    
      fc2:
        _target_: torch.nn.Linear
        in_features: 128 # 64
        out_features: ${model.autoencoder.latent_dim} # 64
        bias: False

      BN2:
        _target_: torch.nn.BatchNorm1d
        num_features: ${model.autoencoder.encoder_cnn.encoder_layers.mlp_layers.fc2.out_features}

decoder_cnn:
  _target_: models.modules.resnet_ae.Decoder
  latent_dim: ${model.autoencoder.latent_dim}
  width: ${model.autoencoder.width}
  height: ${model.autoencoder.height}
  num_channels: ${model.autoencoder.num_channels}

  mlp_layers:
      fc1:
        _target_: torch.nn.Linear
        in_features: ${model.autoencoder.latent_dim} # 128
        out_features: 128
        bias: False

      # BN1:
      #   _target_: torch.nn.BatchNorm1d
      #   num_features: ${model.autoencoder.decoder_cnn.mlp_layers.fc1.out_features}

      fc1_nonlinearity:
        _target_: torch.nn.LeakyReLU
        negative_slope: 0.1
    
      fc2:
        _target_: torch.nn.Linear
        in_features: 128
        out_features: 1024 # 64x4x4
        bias: False
      
      # BN2:
      #   _target_: torch.nn.BatchNorm1d
      #   num_features: ${model.autoencoder.decoder_cnn.mlp_layers.fc2.out_features}

      fc2_nonlinearity:
        _target_: torch.nn.LeakyReLU

  decoder_layers:
    Upsample1:
      _target_: torch.nn.Upsample
      scale_factor: 2  # Upsample factor, adjust as needed
      mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
      # align_corners: false  # Set to false to match behavior of most frameworks
      # in_channelsx4x4 --> in_channelsx8x8

    Conv1:
      _target_: torch.nn.Conv2d
      in_channels: 64
      out_channels: 64
      kernel_size: 4
      stride: 1
      padding: 1
      # in_channelsx8x8 --> out_channelsx7x7

    # BN1:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: 64

    ReLU1:
      _target_: torch.nn.ReLU

    Upsample2:
      _target_: torch.nn.Upsample
      scale_factor: 2  # Upsample factor, adjust as needed
      mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
      # align_corners: false  # Set to false to match behavior of most frameworks
      # in_channelsx7x7 --> in_channelsx14x14

    Conv2:
      _target_: torch.nn.Conv2d
      in_channels: 64
      out_channels: 32
      kernel_size: 5 # Adjust the kernel size as needed
      stride: 1
      padding: 2
      # in_channelsx14x14 --> out_channelsx14x14

    # BN2:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: 32

    ReLU2:
      _target_: torch.nn.ReLU

    Upsample3:
      _target_: torch.nn.Upsample
      scale_factor: 2  # Upsample factor, adjust as needed
      mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
      # align_corners: false  # Set to false to match behavior of most frameworks
      # in_channelsx14x14 --> in_channelsx28x28

    Conv3:
      _target_: torch.nn.Conv2d
      in_channels: 32
      out_channels: 3
      kernel_size: 3
      stride: 1
      padding: 1
      # in_channelsx28x28 --> out_channelsx28x28

    # BN3:
    #   _target_: torch.nn.BatchNorm2d
    #   num_features: ${model.autoencoder.decoder_cnn.decoder_layers.Conv3.out_channels}

    # ReLU3:
    #   _target_: torch.nn.ReLU

    # Upsample4:
    #   _target_: torch.nn.Upsample
    #   scale_factor: 2  # Upsample factor, adjust as needed
    #   mode: ${model.autoencoder.upsampling_interpolation}  # Use nearest/bilinear/etc. interpolation for upsampling
    #   # align_corners: false  # Set to false to match behavior of most frameworks
    #   # in_channelsx14x14 --> in_channelsx28x28

    # Conv4:
    #   _target_: torch.nn.Conv2d
    #   in_channels: ${model.autoencoder.decoder_cnn.decoder_layers.Conv3.out_channels}
    #   out_channels: ${model.autoencoder.num_channels}
    #   kernel_size: 3
    #   stride: 1
    #   padding: 1
    #   # in_channelsx28x28 --> out_channelsx28x28

    # ReLU4:
    #   _target_: torch.nn.ReLU
